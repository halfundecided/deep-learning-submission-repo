{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "edzMEOoUoxMc"
   },
   "source": [
    "# Home 4: Build a CNN for image recognition.\n",
    "\n",
    "### Name: Mijeong Ban\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vt3n_AWBoxMh"
   },
   "source": [
    "## 0. You will do the following:\n",
    "\n",
    "1. Read, complete, and run the code.\n",
    "\n",
    "2. **Make substantial improvements** to maximize the accurcy.\n",
    "    \n",
    "3. Convert the .IPYNB file to .HTML file.\n",
    "\n",
    "    * The HTML file must contain the code and the output after execution.\n",
    "    \n",
    "    * Missing **the output after execution** will not be graded.\n",
    "    \n",
    "4. Upload this .HTML file to your Google Drive, Dropbox, or Github repo. (If you submit the file to Google Drive or Dropbox, you must make the file \"open-access\". The delay caused by \"deny of access\" may result in late penalty.)\n",
    "\n",
    "4. Submit the link to this .HTML file to Canvas.\n",
    "\n",
    "    * Example: https://github.com/wangshusen/CS583-2020S/blob/master/homework/HM4/HM4.html\n",
    "\n",
    "\n",
    "## Requirements:\n",
    "\n",
    "1. You can use whatever CNN architecture, including VGG, Inception, and ResNet. However, you must build the networks layer by layer. You must NOT import the archetectures from ```keras.applications```.\n",
    "\n",
    "2. Make sure ```BatchNormalization``` is between a ```Conv```/```Dense``` layer and an ```activation``` layer.\n",
    "\n",
    "3. If you want to regularize a ```Conv```/```Dense``` layer, you should place a ```Dropout``` layer **before** the ```Conv```/```Dense``` layer.\n",
    "\n",
    "4. An accuracy above 70% is considered reasonable. An accuracy above 80% is considered good. Without data augmentation, achieving 80% accuracy is difficult.\n",
    "\n",
    "\n",
    "## Google Colab\n",
    "\n",
    "- If you do not have GPU, the training of a CNN can be slow. Google Colab is a good option.\n",
    "\n",
    "- Keep in mind that you must download it as an IPYNB file and then use IPython Notebook to convert it to HTML.\n",
    "\n",
    "- Also keep in mind that the IPYNB and HTML files must contain the outputs. (Otherwise, the instructor will not be able to know the correctness and performance.) Do the followings to keep the outputs.\n",
    "\n",
    "- In Colab, go to ```Runtime``` --> ```Change runtime type``` --> Do NOT check ```Omit code cell output when saving this notebook```. In this way, the downloaded IPYNB file contains the outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bbVAZj4PoxMk"
   },
   "source": [
    "## 1. Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "K3kOy-Y6oxMo"
   },
   "source": [
    "### 1.1. Load data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "colab_type": "code",
    "id": "VIVYzEU0oxMr",
    "outputId": "5f76bbaa-9482-4c4d-a3db-c59bdce68037"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of x_train: (50000, 32, 32, 3)\n",
      "shape of y_train: (50000, 1)\n",
      "shape of x_test: (10000, 32, 32, 3)\n",
      "shape of y_test: (10000, 1)\n",
      "number of classes: 10\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import cifar10\n",
    "import numpy\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "print('shape of x_train: ' + str(x_train.shape))\n",
    "print('shape of y_train: ' + str(y_train.shape))\n",
    "print('shape of x_test: ' + str(x_test.shape))\n",
    "print('shape of y_test: ' + str(y_test.shape))\n",
    "print('number of classes: ' + str(numpy.max(y_train) - numpy.min(y_train) + 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FQqZi6FwoxM4"
   },
   "source": [
    "### 1.2. One-hot encode the labels\n",
    "\n",
    "In the input, a label is a scalar in $\\{0, 1, \\cdots , 9\\}$. One-hot encode transform such a scalar to a $10$-dim vector. E.g., a scalar ```y_train[j]=3``` is transformed to the vector ```y_train_vec[j]=[0, 0, 0, 1, 0, 0, 0, 0, 0, 0]```.\n",
    "\n",
    "1. Define a function ```to_one_hot``` that transforms an $n\\times 1$ array to a $n\\times 10$ matrix.\n",
    "\n",
    "2. Apply the function to ```y_train``` and ```y_test```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "colab_type": "code",
    "id": "pBX7o-lhoxM7",
    "outputId": "2cd9276e-d93e-47b2-ef4b-19066a1abc3f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of y_train_vec: (50000, 10)\n",
      "Shape of y_test_vec: (10000, 10)\n",
      "[6]\n",
      "[0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def to_one_hot(y, num_class=10):\n",
    "    results = np.zeros((len(y), num_class))\n",
    "    for i, label in enumerate(y):\n",
    "        results[i, label] = 1.\n",
    "    return results\n",
    "\n",
    "y_train_vec = to_one_hot(y_train)\n",
    "y_test_vec = to_one_hot(y_test)\n",
    "\n",
    "print('Shape of y_train_vec: ' + str(y_train_vec.shape))\n",
    "print('Shape of y_test_vec: ' + str(y_test_vec.shape))\n",
    "\n",
    "print(y_train[0])\n",
    "print(y_train_vec[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B2tLYMgHoxND"
   },
   "source": [
    "#### Remark: the outputs should be\n",
    "* Shape of y_train_vec: (50000, 10)\n",
    "* Shape of y_test_vec: (10000, 10)\n",
    "* [6]\n",
    "* [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k4XdOm2voxNF"
   },
   "source": [
    "### 1.3. Randomly partition the training set to training and validation sets\n",
    "\n",
    "Randomly partition the 50K training samples to 2 sets:\n",
    "* a training set containing 40K samples\n",
    "* a validation set containing 10K samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "colab_type": "code",
    "id": "3mE2ec9XoxNI",
    "outputId": "9ec852f1-1ed1-49a8-94d5-59be37dac440"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x_tr: (40000, 32, 32, 3)\n",
      "Shape of y_tr: (40000, 10)\n",
      "Shape of x_val: (10000, 32, 32, 3)\n",
      "Shape of y_val: (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "rand_indices = numpy.random.permutation(50000)\n",
    "train_indices = rand_indices[0:40000]\n",
    "valid_indices = rand_indices[40000:50000]\n",
    "\n",
    "x_val = x_train[valid_indices, :]\n",
    "y_val = y_train_vec[valid_indices, :]\n",
    "\n",
    "x_tr = x_train[train_indices, :]\n",
    "y_tr = y_train_vec[train_indices, :]\n",
    "\n",
    "print('Shape of x_tr: ' + str(x_tr.shape))\n",
    "print('Shape of y_tr: ' + str(y_tr.shape))\n",
    "print('Shape of x_val: ' + str(x_val.shape))\n",
    "print('Shape of y_val: ' + str(y_val.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g2fL_tRmoxNQ"
   },
   "source": [
    "## 2. Build a CNN and tune its hyper-parameters\n",
    "\n",
    "1. Build a convolutional neural network model\n",
    "2. Use the validation data to tune the hyper-parameters (e.g., network structure, and optimization algorithm)\n",
    "    * Do NOT use test data for hyper-parameter tuning!!!\n",
    "3. Try to achieve a validation accuracy as high as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rIEI7m7roxNS"
   },
   "source": [
    "### Remark: \n",
    "\n",
    "The following CNN is just an example. You are supposed to make **substantial improvements** such as:\n",
    "* Add more layers.\n",
    "* Use regularizations, e.g., dropout.\n",
    "* Use batch normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "KKz4tUbooxNU",
    "outputId": "4049c1d5-89c3-4138-80d9-002c3c72b535"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_8 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 8, 8, 128)         73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 8, 8, 128)         147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 8, 8, 128)         147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               262272    \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 700,970\n",
      "Trainable params: 699,562\n",
      "Non-trainable params: 1,408\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Conv2D, Activation, MaxPooling2D, BatchNormalization, Flatten, Dense, Dropout\n",
    "from keras.models import Sequential\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same', input_shape=(32, 32, 3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "# model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(32, (3, 3), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(2, 2))\n",
    "\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "# model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "# model.add(MaxPooling2D(2, 2))\n",
    "model.add(Conv2D(128, (3, 3), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "# model.add(MaxPooling2D(2, 2))\n",
    "model.add(Conv2D(128, (3, 3), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(2, 2))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(128))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0SMzfNjzoxNa"
   },
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "\n",
    "learning_rate = 1E-3 # to be tuned!\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.RMSprop(lr=learning_rate),\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rzu-j_REoxNg"
   },
   "outputs": [],
   "source": [
    "# Data Augmentation\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=20, \n",
    "    width_shift_range=0.2, \n",
    "    height_shift_range=0.2, \n",
    "    zoom_range=0.1, \n",
    "    horizontal_flip=True\n",
    ")\n",
    "train_datagen.fit(x_tr)\n",
    "train_generator = train_datagen.flow(x_tr, y_tr, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "cSInP8WRoxNm",
    "outputId": "8b7f24ad-a500-4ea2-d43c-630f99196451"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "625/625 [==============================] - 24s 38ms/step - loss: 1.6762 - acc: 0.3813 - val_loss: 2.9124 - val_acc: 0.3164\n",
      "Epoch 2/100\n",
      "625/625 [==============================] - 22s 35ms/step - loss: 1.3523 - acc: 0.5062 - val_loss: 1.2796 - val_acc: 0.5466\n",
      "Epoch 3/100\n",
      "625/625 [==============================] - 22s 35ms/step - loss: 1.2129 - acc: 0.5657 - val_loss: 1.4402 - val_acc: 0.5433\n",
      "Epoch 4/100\n",
      "625/625 [==============================] - 22s 35ms/step - loss: 1.1253 - acc: 0.6003 - val_loss: 1.2614 - val_acc: 0.5824\n",
      "Epoch 5/100\n",
      "625/625 [==============================] - 22s 35ms/step - loss: 1.0514 - acc: 0.6268 - val_loss: 1.0273 - val_acc: 0.6694\n",
      "Epoch 6/100\n",
      "625/625 [==============================] - 22s 35ms/step - loss: 0.9966 - acc: 0.6486 - val_loss: 1.4241 - val_acc: 0.5774\n",
      "Epoch 7/100\n",
      "625/625 [==============================] - 22s 35ms/step - loss: 0.9546 - acc: 0.6639 - val_loss: 1.5385 - val_acc: 0.5464\n",
      "Epoch 8/100\n",
      "625/625 [==============================] - 22s 35ms/step - loss: 0.9154 - acc: 0.6788 - val_loss: 1.2217 - val_acc: 0.6267\n",
      "Epoch 9/100\n",
      "625/625 [==============================] - 22s 35ms/step - loss: 0.8832 - acc: 0.6919 - val_loss: 0.9355 - val_acc: 0.7058\n",
      "Epoch 10/100\n",
      "625/625 [==============================] - 22s 35ms/step - loss: 0.8527 - acc: 0.7002 - val_loss: 0.7853 - val_acc: 0.7316\n",
      "Epoch 11/100\n",
      "625/625 [==============================] - 22s 35ms/step - loss: 0.8336 - acc: 0.7089 - val_loss: 0.9421 - val_acc: 0.7096\n",
      "Epoch 12/100\n",
      "625/625 [==============================] - 22s 35ms/step - loss: 0.8043 - acc: 0.7188 - val_loss: 0.8150 - val_acc: 0.7366\n",
      "Epoch 13/100\n",
      "625/625 [==============================] - 22s 35ms/step - loss: 0.7952 - acc: 0.7248 - val_loss: 1.0012 - val_acc: 0.7056\n",
      "Epoch 14/100\n",
      "625/625 [==============================] - 22s 36ms/step - loss: 0.7743 - acc: 0.7297 - val_loss: 1.4257 - val_acc: 0.6402\n",
      "Epoch 15/100\n",
      "625/625 [==============================] - 22s 35ms/step - loss: 0.7578 - acc: 0.7373 - val_loss: 0.8414 - val_acc: 0.7373\n",
      "Epoch 16/100\n",
      "625/625 [==============================] - 22s 35ms/step - loss: 0.7475 - acc: 0.7413 - val_loss: 0.7472 - val_acc: 0.7582\n",
      "Epoch 17/100\n",
      "625/625 [==============================] - 22s 35ms/step - loss: 0.7368 - acc: 0.7456 - val_loss: 0.7528 - val_acc: 0.7646\n",
      "Epoch 18/100\n",
      "625/625 [==============================] - 22s 35ms/step - loss: 0.7193 - acc: 0.7509 - val_loss: 0.8641 - val_acc: 0.7327\n",
      "Epoch 19/100\n",
      "625/625 [==============================] - 22s 35ms/step - loss: 0.7107 - acc: 0.7563 - val_loss: 0.6995 - val_acc: 0.7743\n",
      "Epoch 20/100\n",
      "625/625 [==============================] - 22s 35ms/step - loss: 0.7005 - acc: 0.7582 - val_loss: 0.7210 - val_acc: 0.7825\n",
      "Epoch 21/100\n",
      "625/625 [==============================] - 22s 34ms/step - loss: 0.6819 - acc: 0.7669 - val_loss: 0.9536 - val_acc: 0.7369\n",
      "Epoch 22/100\n",
      "625/625 [==============================] - 22s 35ms/step - loss: 0.6773 - acc: 0.7665 - val_loss: 0.5937 - val_acc: 0.8086\n",
      "Epoch 23/100\n",
      "625/625 [==============================] - 22s 35ms/step - loss: 0.6712 - acc: 0.7702 - val_loss: 0.6620 - val_acc: 0.7860\n",
      "Epoch 24/100\n",
      "625/625 [==============================] - 22s 35ms/step - loss: 0.6650 - acc: 0.7714 - val_loss: 0.6650 - val_acc: 0.7913\n",
      "Epoch 25/100\n",
      "625/625 [==============================] - 22s 35ms/step - loss: 0.6546 - acc: 0.7735 - val_loss: 0.6840 - val_acc: 0.7862\n",
      "Epoch 26/100\n",
      "625/625 [==============================] - 22s 34ms/step - loss: 0.6471 - acc: 0.7785 - val_loss: 0.5702 - val_acc: 0.8177\n",
      "Epoch 27/100\n",
      "625/625 [==============================] - 22s 35ms/step - loss: 0.6403 - acc: 0.7804 - val_loss: 0.7491 - val_acc: 0.7680\n",
      "Epoch 28/100\n",
      "625/625 [==============================] - 22s 35ms/step - loss: 0.6346 - acc: 0.7826 - val_loss: 0.7684 - val_acc: 0.7843\n",
      "Epoch 29/100\n",
      "625/625 [==============================] - 22s 35ms/step - loss: 0.6293 - acc: 0.7811 - val_loss: 0.6683 - val_acc: 0.8012\n",
      "Epoch 30/100\n",
      "625/625 [==============================] - 22s 35ms/step - loss: 0.6273 - acc: 0.7813 - val_loss: 0.7033 - val_acc: 0.7853\n",
      "Epoch 31/100\n",
      "625/625 [==============================] - 22s 35ms/step - loss: 0.6216 - acc: 0.7875 - val_loss: 0.6581 - val_acc: 0.8017\n",
      "Epoch 32/100\n",
      "625/625 [==============================] - 22s 34ms/step - loss: 0.6173 - acc: 0.7861 - val_loss: 0.5720 - val_acc: 0.8266\n",
      "Epoch 33/100\n",
      "625/625 [==============================] - 21s 34ms/step - loss: 0.6166 - acc: 0.7883 - val_loss: 0.6968 - val_acc: 0.7914\n",
      "Epoch 34/100\n",
      "625/625 [==============================] - 22s 35ms/step - loss: 0.6040 - acc: 0.7914 - val_loss: 0.8176 - val_acc: 0.7756\n",
      "Epoch 35/100\n",
      "625/625 [==============================] - 22s 35ms/step - loss: 0.5970 - acc: 0.7950 - val_loss: 0.5443 - val_acc: 0.8321\n",
      "Epoch 36/100\n",
      "625/625 [==============================] - 22s 35ms/step - loss: 0.5888 - acc: 0.7973 - val_loss: 0.7012 - val_acc: 0.7907\n",
      "Epoch 37/100\n",
      "625/625 [==============================] - 22s 35ms/step - loss: 0.5889 - acc: 0.7973 - val_loss: 0.8287 - val_acc: 0.7810\n",
      "Epoch 38/100\n",
      "625/625 [==============================] - 22s 35ms/step - loss: 0.5878 - acc: 0.7971 - val_loss: 0.7571 - val_acc: 0.7836\n",
      "Epoch 39/100\n",
      "625/625 [==============================] - 22s 35ms/step - loss: 0.5839 - acc: 0.7980 - val_loss: 0.5898 - val_acc: 0.8220\n",
      "Epoch 40/100\n",
      "625/625 [==============================] - 22s 35ms/step - loss: 0.5821 - acc: 0.7995 - val_loss: 0.6636 - val_acc: 0.7930\n",
      "Epoch 41/100\n",
      "625/625 [==============================] - 22s 35ms/step - loss: 0.5724 - acc: 0.8029 - val_loss: 0.6634 - val_acc: 0.7980\n",
      "Epoch 42/100\n",
      "625/625 [==============================] - 23s 36ms/step - loss: 0.5705 - acc: 0.8033 - val_loss: 0.6532 - val_acc: 0.8037\n",
      "Epoch 43/100\n",
      "625/625 [==============================] - 22s 36ms/step - loss: 0.5663 - acc: 0.8059 - val_loss: 0.6199 - val_acc: 0.8096\n",
      "Epoch 44/100\n",
      "625/625 [==============================] - 22s 35ms/step - loss: 0.5629 - acc: 0.8053 - val_loss: 0.5037 - val_acc: 0.8407\n",
      "Epoch 45/100\n",
      "625/625 [==============================] - 22s 35ms/step - loss: 0.5593 - acc: 0.8074 - val_loss: 0.6683 - val_acc: 0.8022\n",
      "Epoch 46/100\n",
      "625/625 [==============================] - 22s 35ms/step - loss: 0.5598 - acc: 0.8059 - val_loss: 0.5522 - val_acc: 0.8280\n",
      "Epoch 47/100\n",
      "625/625 [==============================] - 22s 35ms/step - loss: 0.5546 - acc: 0.8088 - val_loss: 0.6232 - val_acc: 0.8098\n",
      "Epoch 48/100\n",
      "625/625 [==============================] - 22s 35ms/step - loss: 0.5480 - acc: 0.8114 - val_loss: 0.6028 - val_acc: 0.8238\n",
      "Epoch 49/100\n",
      "625/625 [==============================] - 22s 35ms/step - loss: 0.5485 - acc: 0.8141 - val_loss: 0.5800 - val_acc: 0.8276\n",
      "Epoch 50/100\n",
      "625/625 [==============================] - 22s 35ms/step - loss: 0.5432 - acc: 0.8134 - val_loss: 0.5599 - val_acc: 0.8274\n",
      "Epoch 51/100\n",
      "625/625 [==============================] - 22s 35ms/step - loss: 0.5355 - acc: 0.8152 - val_loss: 0.6135 - val_acc: 0.8138\n",
      "Epoch 52/100\n",
      "625/625 [==============================] - 22s 35ms/step - loss: 0.5417 - acc: 0.8145 - val_loss: 0.6450 - val_acc: 0.7962\n",
      "Epoch 53/100\n",
      "625/625 [==============================] - 22s 35ms/step - loss: 0.5382 - acc: 0.8153 - val_loss: 0.5661 - val_acc: 0.8279\n",
      "Epoch 54/100\n",
      "625/625 [==============================] - 22s 35ms/step - loss: 0.5354 - acc: 0.8164 - val_loss: 0.6616 - val_acc: 0.8012\n",
      "Epoch 55/100\n",
      "625/625 [==============================] - 22s 35ms/step - loss: 0.5287 - acc: 0.8172 - val_loss: 0.4987 - val_acc: 0.8538\n",
      "Epoch 56/100\n",
      "625/625 [==============================] - 22s 35ms/step - loss: 0.5270 - acc: 0.8199 - val_loss: 0.6518 - val_acc: 0.8095\n",
      "Epoch 57/100\n",
      "625/625 [==============================] - 22s 35ms/step - loss: 0.5289 - acc: 0.8183 - val_loss: 0.5228 - val_acc: 0.8331\n",
      "Epoch 58/100\n",
      "625/625 [==============================] - 22s 35ms/step - loss: 0.5223 - acc: 0.8206 - val_loss: 0.5033 - val_acc: 0.8416\n",
      "Epoch 59/100\n",
      "625/625 [==============================] - 22s 35ms/step - loss: 0.5282 - acc: 0.8192 - val_loss: 0.6427 - val_acc: 0.8204\n",
      "Epoch 60/100\n",
      "625/625 [==============================] - 22s 35ms/step - loss: 0.5240 - acc: 0.8206 - val_loss: 0.5579 - val_acc: 0.8387\n",
      "Epoch 61/100\n",
      "625/625 [==============================] - 22s 35ms/step - loss: 0.5186 - acc: 0.8217 - val_loss: 0.6613 - val_acc: 0.8129\n",
      "Epoch 62/100\n",
      "625/625 [==============================] - 22s 35ms/step - loss: 0.5145 - acc: 0.8225 - val_loss: 0.5443 - val_acc: 0.8397\n",
      "Epoch 63/100\n",
      "625/625 [==============================] - 22s 35ms/step - loss: 0.5119 - acc: 0.8237 - val_loss: 0.6899 - val_acc: 0.8198\n",
      "Epoch 64/100\n",
      "625/625 [==============================] - 22s 35ms/step - loss: 0.5128 - acc: 0.8238 - val_loss: 0.5703 - val_acc: 0.8347\n",
      "Epoch 65/100\n",
      "625/625 [==============================] - 22s 35ms/step - loss: 0.5060 - acc: 0.8247 - val_loss: 0.5492 - val_acc: 0.8396\n",
      "Epoch 66/100\n",
      "625/625 [==============================] - 22s 35ms/step - loss: 0.5096 - acc: 0.8237 - val_loss: 0.6963 - val_acc: 0.8059\n",
      "Epoch 67/100\n",
      "625/625 [==============================] - 22s 36ms/step - loss: 0.5041 - acc: 0.8253 - val_loss: 0.5986 - val_acc: 0.8253\n",
      "Epoch 68/100\n",
      "625/625 [==============================] - 23s 36ms/step - loss: 0.5017 - acc: 0.8265 - val_loss: 0.5290 - val_acc: 0.8458\n",
      "Epoch 69/100\n",
      "625/625 [==============================] - 22s 36ms/step - loss: 0.4991 - acc: 0.8288 - val_loss: 0.5135 - val_acc: 0.8441\n",
      "Epoch 70/100\n",
      "625/625 [==============================] - 22s 36ms/step - loss: 0.5023 - acc: 0.8277 - val_loss: 0.5756 - val_acc: 0.8372\n",
      "Epoch 71/100\n",
      "625/625 [==============================] - 23s 36ms/step - loss: 0.5010 - acc: 0.8285 - val_loss: 0.5130 - val_acc: 0.8463\n",
      "Epoch 72/100\n",
      "625/625 [==============================] - 22s 35ms/step - loss: 0.4984 - acc: 0.8275 - val_loss: 0.6621 - val_acc: 0.8198\n",
      "Epoch 73/100\n",
      "625/625 [==============================] - 22s 35ms/step - loss: 0.4967 - acc: 0.8299 - val_loss: 0.4600 - val_acc: 0.8591\n",
      "Epoch 74/100\n",
      "625/625 [==============================] - 22s 35ms/step - loss: 0.4872 - acc: 0.8320 - val_loss: 0.5276 - val_acc: 0.8388\n",
      "Epoch 75/100\n",
      "625/625 [==============================] - 22s 36ms/step - loss: 0.4939 - acc: 0.8289 - val_loss: 0.6063 - val_acc: 0.8174\n",
      "Epoch 76/100\n",
      "625/625 [==============================] - 22s 35ms/step - loss: 0.4865 - acc: 0.8320 - val_loss: 0.5067 - val_acc: 0.8463\n",
      "Epoch 77/100\n",
      "625/625 [==============================] - 22s 35ms/step - loss: 0.4829 - acc: 0.8337 - val_loss: 0.6753 - val_acc: 0.8209\n",
      "Epoch 78/100\n",
      "625/625 [==============================] - 22s 35ms/step - loss: 0.4866 - acc: 0.8343 - val_loss: 0.5439 - val_acc: 0.8357\n",
      "Epoch 79/100\n",
      "625/625 [==============================] - 22s 36ms/step - loss: 0.4778 - acc: 0.8352 - val_loss: 0.5296 - val_acc: 0.8437\n",
      "Epoch 80/100\n",
      "625/625 [==============================] - 22s 35ms/step - loss: 0.4731 - acc: 0.8364 - val_loss: 0.5680 - val_acc: 0.8390\n",
      "Epoch 81/100\n",
      "625/625 [==============================] - 22s 35ms/step - loss: 0.4759 - acc: 0.8353 - val_loss: 0.5670 - val_acc: 0.8381\n",
      "Epoch 82/100\n",
      "625/625 [==============================] - 22s 35ms/step - loss: 0.4762 - acc: 0.8347 - val_loss: 0.4882 - val_acc: 0.8591\n",
      "Epoch 83/100\n",
      "625/625 [==============================] - 22s 35ms/step - loss: 0.4791 - acc: 0.8349 - val_loss: 0.4932 - val_acc: 0.8553\n",
      "Epoch 84/100\n",
      "625/625 [==============================] - 22s 35ms/step - loss: 0.4698 - acc: 0.8391 - val_loss: 0.5462 - val_acc: 0.8471\n",
      "Epoch 85/100\n",
      "625/625 [==============================] - 22s 35ms/step - loss: 0.4756 - acc: 0.8360 - val_loss: 0.4755 - val_acc: 0.8577\n",
      "Epoch 86/100\n",
      "625/625 [==============================] - 22s 35ms/step - loss: 0.4721 - acc: 0.8360 - val_loss: 0.5132 - val_acc: 0.8476\n",
      "Epoch 87/100\n",
      "625/625 [==============================] - 22s 35ms/step - loss: 0.4787 - acc: 0.8360 - val_loss: 0.4970 - val_acc: 0.8526\n",
      "Epoch 88/100\n",
      "625/625 [==============================] - 22s 34ms/step - loss: 0.4677 - acc: 0.8366 - val_loss: 0.5833 - val_acc: 0.8365\n",
      "Epoch 89/100\n",
      "625/625 [==============================] - 22s 35ms/step - loss: 0.4696 - acc: 0.8372 - val_loss: 0.6982 - val_acc: 0.8282\n",
      "Epoch 90/100\n",
      "625/625 [==============================] - 22s 35ms/step - loss: 0.4591 - acc: 0.8412 - val_loss: 0.5506 - val_acc: 0.8461\n",
      "Epoch 91/100\n",
      "625/625 [==============================] - 22s 35ms/step - loss: 0.4613 - acc: 0.8410 - val_loss: 0.5378 - val_acc: 0.8455\n",
      "Epoch 92/100\n",
      "625/625 [==============================] - 21s 34ms/step - loss: 0.4674 - acc: 0.8412 - val_loss: 0.4881 - val_acc: 0.8580\n",
      "Epoch 93/100\n",
      "625/625 [==============================] - 22s 35ms/step - loss: 0.4599 - acc: 0.8414 - val_loss: 0.5452 - val_acc: 0.8498\n",
      "Epoch 94/100\n",
      "625/625 [==============================] - 22s 35ms/step - loss: 0.4551 - acc: 0.8431 - val_loss: 0.7366 - val_acc: 0.8110\n",
      "Epoch 95/100\n",
      "625/625 [==============================] - 22s 35ms/step - loss: 0.4574 - acc: 0.8402 - val_loss: 0.5190 - val_acc: 0.8578\n",
      "Epoch 96/100\n",
      "625/625 [==============================] - 22s 35ms/step - loss: 0.4611 - acc: 0.8417 - val_loss: 0.4281 - val_acc: 0.8693\n",
      "Epoch 97/100\n",
      "625/625 [==============================] - 22s 35ms/step - loss: 0.4565 - acc: 0.8433 - val_loss: 0.5107 - val_acc: 0.8505\n",
      "Epoch 98/100\n",
      "625/625 [==============================] - 22s 35ms/step - loss: 0.4600 - acc: 0.8419 - val_loss: 0.5148 - val_acc: 0.8512\n",
      "Epoch 99/100\n",
      "625/625 [==============================] - 22s 35ms/step - loss: 0.4570 - acc: 0.8428 - val_loss: 0.6470 - val_acc: 0.8262\n",
      "Epoch 100/100\n",
      "625/625 [==============================] - 22s 35ms/step - loss: 0.4579 - acc: 0.8412 - val_loss: 0.6248 - val_acc: 0.8324\n"
     ]
    }
   ],
   "source": [
    "# history = model.fit(x_tr, y_tr, batch_size=32, epochs=10, validation_data=(x_val, y_val))\n",
    "step = int(x_tr.shape[0] / 64)\n",
    "history = model.fit_generator(train_generator, steps_per_epoch=step, epochs = 100, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 573
    },
    "colab_type": "code",
    "id": "Syydo60hoxNr",
    "outputId": "f7da2d8d-172b-4b2a-b054-80731f671fa8"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.title('Training & Validation Accuracy')\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.title('Training & Validation Loss')\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yMBlu1wBoxNz"
   },
   "source": [
    "## 3. Train (again) and evaluate the model\n",
    "\n",
    "- To this end, you have found the \"best\" hyper-parameters. \n",
    "- Now, fix the hyper-parameters and train the network on the entire training set (all the 50K training samples)\n",
    "- Evaluate your model on the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kEQTweV9oxN1"
   },
   "source": [
    "### 3.1. Train the model on the entire training set\n",
    "\n",
    "Why? Previously, you used 40K samples for training; you wasted 10K samples for the sake of hyper-parameter tuning. Now you already know the hyper-parameters, so why not using all the 50K samples for training?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6p34IRgmoxN2"
   },
   "outputs": [],
   "source": [
    "# <Compile your model again (using the same hyper-parameters)>\n",
    "learning_rate = 1E-3\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.RMSprop(lr=learning_rate),\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "UzpEH84eoxN8",
    "outputId": "c094145c-ae90-4309-bdda-700f81e5d968"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "100/100 [==============================] - 5s 46ms/step - loss: 0.4696 - acc: 0.8355\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 3s 35ms/step - loss: 0.4591 - acc: 0.8425\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 3s 34ms/step - loss: 0.4556 - acc: 0.8403\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 3s 35ms/step - loss: 0.4945 - acc: 0.8253\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 3s 35ms/step - loss: 0.4938 - acc: 0.8313\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 3s 34ms/step - loss: 0.4811 - acc: 0.8309\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 3s 35ms/step - loss: 0.4966 - acc: 0.8312\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 3s 35ms/step - loss: 0.4902 - acc: 0.8377\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 4s 35ms/step - loss: 0.4789 - acc: 0.8395\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 3s 35ms/step - loss: 0.4725 - acc: 0.8411\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 3s 34ms/step - loss: 0.4686 - acc: 0.8337\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 3s 34ms/step - loss: 0.4772 - acc: 0.8383\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 3s 34ms/step - loss: 0.4481 - acc: 0.8469\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 3s 34ms/step - loss: 0.4847 - acc: 0.8345\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 3s 34ms/step - loss: 0.4681 - acc: 0.8381\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 3s 35ms/step - loss: 0.4501 - acc: 0.8395\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 3s 34ms/step - loss: 0.4657 - acc: 0.8392\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 3s 34ms/step - loss: 0.4685 - acc: 0.8406\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 3s 35ms/step - loss: 0.4882 - acc: 0.8300\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 3s 35ms/step - loss: 0.4815 - acc: 0.8361\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 3s 35ms/step - loss: 0.4722 - acc: 0.8367\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 3s 35ms/step - loss: 0.4784 - acc: 0.8309\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 3s 34ms/step - loss: 0.4648 - acc: 0.8406\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 4s 36ms/step - loss: 0.4790 - acc: 0.8348\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 3s 35ms/step - loss: 0.4626 - acc: 0.8363\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 3s 34ms/step - loss: 0.4736 - acc: 0.8373\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 3s 34ms/step - loss: 0.4530 - acc: 0.8406\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 3s 34ms/step - loss: 0.4694 - acc: 0.8405\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 3s 34ms/step - loss: 0.4557 - acc: 0.8439\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 3s 34ms/step - loss: 0.4717 - acc: 0.8406\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 3s 34ms/step - loss: 0.4621 - acc: 0.8408\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 3s 34ms/step - loss: 0.4745 - acc: 0.8375\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 3s 34ms/step - loss: 0.4569 - acc: 0.8394\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 3s 34ms/step - loss: 0.4608 - acc: 0.8423\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 3s 34ms/step - loss: 0.4740 - acc: 0.8348\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 3s 34ms/step - loss: 0.4791 - acc: 0.8361\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 3s 34ms/step - loss: 0.4697 - acc: 0.8408\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 3s 34ms/step - loss: 0.4622 - acc: 0.8389\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 3s 34ms/step - loss: 0.4455 - acc: 0.8480\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 3s 35ms/step - loss: 0.4817 - acc: 0.8337\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - 3s 34ms/step - loss: 0.4596 - acc: 0.8433\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - 3s 34ms/step - loss: 0.4659 - acc: 0.8381\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - 4s 35ms/step - loss: 0.4604 - acc: 0.8453\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - 3s 34ms/step - loss: 0.4721 - acc: 0.8394\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - 3s 35ms/step - loss: 0.4585 - acc: 0.8433\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - 3s 34ms/step - loss: 0.4587 - acc: 0.8397\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - 3s 34ms/step - loss: 0.4641 - acc: 0.8444\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - 3s 34ms/step - loss: 0.4688 - acc: 0.8411\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - 3s 34ms/step - loss: 0.4642 - acc: 0.8427\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - 3s 34ms/step - loss: 0.4665 - acc: 0.8416\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - 3s 34ms/step - loss: 0.4680 - acc: 0.8420\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - 3s 34ms/step - loss: 0.4665 - acc: 0.8375\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - 4s 35ms/step - loss: 0.4570 - acc: 0.8448\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - 3s 35ms/step - loss: 0.4476 - acc: 0.8425\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - 3s 35ms/step - loss: 0.4576 - acc: 0.8425\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - 3s 34ms/step - loss: 0.4592 - acc: 0.8441\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - 3s 33ms/step - loss: 0.4529 - acc: 0.8430\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - 3s 34ms/step - loss: 0.4593 - acc: 0.8444\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - 3s 34ms/step - loss: 0.4773 - acc: 0.8333\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - 3s 34ms/step - loss: 0.4746 - acc: 0.8398\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - 3s 34ms/step - loss: 0.4703 - acc: 0.8389\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - 3s 34ms/step - loss: 0.4883 - acc: 0.8327\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - 3s 34ms/step - loss: 0.4776 - acc: 0.8336\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - 3s 34ms/step - loss: 0.4494 - acc: 0.8409\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - 3s 34ms/step - loss: 0.4573 - acc: 0.8386\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - 3s 34ms/step - loss: 0.4584 - acc: 0.8422\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - 3s 34ms/step - loss: 0.4663 - acc: 0.8425\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - 3s 35ms/step - loss: 0.4677 - acc: 0.8434\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - 3s 34ms/step - loss: 0.4618 - acc: 0.8378\n",
      "Epoch 70/100\n",
      "100/100 [==============================] - 3s 34ms/step - loss: 0.4548 - acc: 0.8409\n",
      "Epoch 71/100\n",
      "100/100 [==============================] - 3s 35ms/step - loss: 0.4472 - acc: 0.8452\n",
      "Epoch 72/100\n",
      "100/100 [==============================] - 3s 35ms/step - loss: 0.4625 - acc: 0.8413\n",
      "Epoch 73/100\n",
      "100/100 [==============================] - 3s 34ms/step - loss: 0.4663 - acc: 0.8416\n",
      "Epoch 74/100\n",
      "100/100 [==============================] - 3s 34ms/step - loss: 0.4544 - acc: 0.8425\n",
      "Epoch 75/100\n",
      "100/100 [==============================] - 3s 34ms/step - loss: 0.4698 - acc: 0.8364\n",
      "Epoch 76/100\n",
      "100/100 [==============================] - 3s 34ms/step - loss: 0.4725 - acc: 0.8378\n",
      "Epoch 77/100\n",
      "100/100 [==============================] - 3s 34ms/step - loss: 0.4768 - acc: 0.8397\n",
      "Epoch 78/100\n",
      "100/100 [==============================] - 3s 34ms/step - loss: 0.4724 - acc: 0.8477\n",
      "Epoch 79/100\n",
      "100/100 [==============================] - 3s 35ms/step - loss: 0.4633 - acc: 0.8403\n",
      "Epoch 80/100\n",
      "100/100 [==============================] - 3s 34ms/step - loss: 0.4552 - acc: 0.8448\n",
      "Epoch 81/100\n",
      "100/100 [==============================] - 3s 34ms/step - loss: 0.4677 - acc: 0.8361\n",
      "Epoch 82/100\n",
      "100/100 [==============================] - 3s 34ms/step - loss: 0.4670 - acc: 0.8380\n",
      "Epoch 83/100\n",
      "100/100 [==============================] - 3s 34ms/step - loss: 0.4616 - acc: 0.8423\n",
      "Epoch 84/100\n",
      "100/100 [==============================] - 3s 34ms/step - loss: 0.4484 - acc: 0.8425\n",
      "Epoch 85/100\n",
      "100/100 [==============================] - 3s 33ms/step - loss: 0.4594 - acc: 0.8392\n",
      "Epoch 86/100\n",
      "100/100 [==============================] - 3s 34ms/step - loss: 0.4551 - acc: 0.8430\n",
      "Epoch 87/100\n",
      "100/100 [==============================] - 3s 34ms/step - loss: 0.4547 - acc: 0.8466\n",
      "Epoch 88/100\n",
      "100/100 [==============================] - 3s 34ms/step - loss: 0.4529 - acc: 0.8452\n",
      "Epoch 89/100\n",
      "100/100 [==============================] - 3s 34ms/step - loss: 0.4616 - acc: 0.8422\n",
      "Epoch 90/100\n",
      "100/100 [==============================] - 3s 35ms/step - loss: 0.4590 - acc: 0.8369\n",
      "Epoch 91/100\n",
      "100/100 [==============================] - 3s 35ms/step - loss: 0.4524 - acc: 0.8448\n",
      "Epoch 92/100\n",
      "100/100 [==============================] - 3s 35ms/step - loss: 0.4419 - acc: 0.8456\n",
      "Epoch 93/100\n",
      "100/100 [==============================] - 3s 34ms/step - loss: 0.4650 - acc: 0.8400\n",
      "Epoch 94/100\n",
      "100/100 [==============================] - 3s 34ms/step - loss: 0.4680 - acc: 0.8431\n",
      "Epoch 95/100\n",
      "100/100 [==============================] - 3s 34ms/step - loss: 0.4363 - acc: 0.8505\n",
      "Epoch 96/100\n",
      "100/100 [==============================] - 3s 34ms/step - loss: 0.4695 - acc: 0.8353\n",
      "Epoch 97/100\n",
      "100/100 [==============================] - 3s 34ms/step - loss: 0.4541 - acc: 0.8495\n",
      "Epoch 98/100\n",
      "100/100 [==============================] - 3s 35ms/step - loss: 0.4338 - acc: 0.8517\n",
      "Epoch 99/100\n",
      "100/100 [==============================] - 3s 35ms/step - loss: 0.4594 - acc: 0.8411\n",
      "Epoch 100/100\n",
      "100/100 [==============================] - 3s 34ms/step - loss: 0.4607 - acc: 0.8428\n"
     ]
    }
   ],
   "source": [
    "# <Train your model on the entire training set (50K samples)>\n",
    "# <Use (x_train, y_train_vec) instead of (x_tr, y_tr)>\n",
    "# <Do NOT use the validation_data option (because now you do not have validation data)>\n",
    "train_datagen.fit(x_train)\n",
    "train_generator = train_datagen.flow(x_train, y_train_vec, batch_size=64)\n",
    "history = model.fit_generator(train_generator, steps_per_epoch=100, epochs = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hUxdHiGwoxOB"
   },
   "source": [
    "### 3.2. Evaluate the model on the test set\n",
    "\n",
    "Do NOT used the test set until now. Make sure that your model parameters and hyper-parameters are independent of the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "LHeP_TqnoxOD",
    "outputId": "851856a9-4365-4bec-89c8-1dc75b9183c0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 137us/step\n",
      "loss = 0.5634610983371735\n",
      "accuracy = 0.8419\n"
     ]
    }
   ],
   "source": [
    "loss_and_acc = model.evaluate(x_test, y_test_vec)\n",
    "print('loss = ' + str(loss_and_acc[0]))\n",
    "print('accuracy = ' + str(loss_and_acc[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7XJh8fRDoxOH"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "HM4.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
